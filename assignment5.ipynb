{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T20:29:28.511333Z",
     "start_time": "2024-10-19T20:29:27.321599Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickg\\AppData\\Local\\Temp\\ipykernel_21668\\3269992828.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T21:20:19.841678Z",
     "start_time": "2024-10-19T21:20:19.836895Z"
    }
   },
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [self.compute_distance(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = self.y_train.iloc[k_indices]  # Use iloc to safely index by position\n",
    "        most_common = self._most_common_label(k_nearest_labels)\n",
    "        return most_common\n",
    "\n",
    "    def compute_distance(self, a, b):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((a - b) ** 2))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(a - b))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown distance metric: {self.distance_metric}\")\n",
    "\n",
    "    def _most_common_label(self, labels):\n",
    "        return pd.Series(labels).mode()[0]\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T20:32:12.642625Z",
     "start_time": "2024-10-19T20:32:12.635713Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def preprocess_data(train_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "\n",
    "    # Drop columns that won't be used\n",
    "    train_data.drop(['CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "    test_data.drop(['CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "    # Define feature columns and target column\n",
    "    feature_cols = ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
    "                    'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "    target_col = 'Exited'\n",
    "\n",
    "    # Separate features and target in training data\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data[target_col]\n",
    "\n",
    "    # Features in the test data\n",
    "    X_test = test_data[feature_cols]\n",
    "\n",
    "    # Preprocessing for numerical data: scaling\n",
    "    numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
    "                          'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Preprocessing for categorical data: one-hot encoding\n",
    "    categorical_features = ['Geography', 'Gender']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Fit and transform the train data\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "    return X_train_preprocessed, y_train, X_test_preprocessed\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T20:32:15.411382Z",
     "start_time": "2024-10-19T20:32:15.405500Z"
    }
   },
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_val)\n",
    "\n",
    "        roc_auc = roc_auc_score(y_val, y_pred)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    return np.mean(roc_auc_scores), np.std(roc_auc_scores)\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T22:54:23.054767Z",
     "start_time": "2024-10-19T21:20:27.182820Z"
    }
   },
   "source": [
    "def custom_grid_search(X, y, param_grid, n_splits=5):\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    \n",
    "    for k in param_grid['k']:\n",
    "        for distance_metric in param_grid['distance_metric']:\n",
    "            knn = KNN(k=k, distance_metric=distance_metric)\n",
    "            mean_score, std_score = cross_validate(X, y, knn, n_splits)\n",
    "            print(f\"Params: k={k}, distance_metric={distance_metric}, Mean ROC AUC: {mean_score}, Std: {std_score}\")\n",
    "\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_params = {'k': k, 'distance_metric': distance_metric}\n",
    "    \n",
    "    return best_params, best_score\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "# Create and evaluate model\n",
    "knn = KNN(k=5, distance_metric='euclidean')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_validate(X, y, knn, n_splits=5)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# Hyperparameters tuning\n",
    "param_grid = {\n",
    "    'k': [3, 5, 7],\n",
    "    'distance_metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "best_params, best_score = custom_grid_search(X, y, param_grid, n_splits=5)\n",
    "print(f\"Best Params: {best_params}, Best ROC AUC: {best_score}\")\n",
    "\n",
    "# Train on full dataset with optimal hyperparameters and make predictions on test set\n",
    "knn = KNN(k=best_params['k'], distance_metric=best_params['distance_metric'])\n",
    "knn.fit(X, y)\n",
    "test_predictions = knn.predict(X_test)\n",
    "\n",
    "# Save test predictions\n",
    "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: (0.772968538595073, 0.0055447682380054646)\n",
      "Params: k=3, distance_metric=euclidean, Mean ROC AUC: 0.7681268484255398, Std: 0.008625182321144568\n",
      "Params: k=3, distance_metric=manhattan, Mean ROC AUC: 0.7645737636794798, Std: 0.00997101111467224\n",
      "Params: k=5, distance_metric=euclidean, Mean ROC AUC: 0.772968538595073, Std: 0.0055447682380054646\n",
      "Params: k=5, distance_metric=manhattan, Mean ROC AUC: 0.7690510478821524, Std: 0.00693751241209164\n",
      "Params: k=7, distance_metric=euclidean, Mean ROC AUC: 0.7744699150850485, Std: 0.006366057741985525\n",
      "Params: k=7, distance_metric=manhattan, Mean ROC AUC: 0.7682608728642004, Std: 0.006169267860072259\n",
      "Best Params: {'k': 7, 'distance_metric': 'euclidean'}, Best ROC AUC: 0.7744699150850485\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs506",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
